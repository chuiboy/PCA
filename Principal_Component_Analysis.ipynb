{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Machine Learning: Principal Component Analysis\n",
    "___\n",
    "\n",
    "#### Summary:\n",
    "Principal Component Analysis is a dimensionality reduction algorithm. It creates new features from the \n",
    "current features where the number of new features is less than the number of original features. The new\n",
    "features are constructed in a way that retain most of the variance. PCA is useful for data compression \n",
    "and visualizing data on a 2D plane or a 3D space. In this notebook we derive the PCA algorithm as well \n",
    "as use the already existing PCA algorithm from sklearn.\n",
    "___\n",
    "#### This notebook will include:\n",
    "1. PCA derivation\n",
    "2. PCA w/ sklearn\n",
    "___\n",
    "#### Reference: \n",
    "\n",
    "Much of what is in this notebook was learned from the Machine Learning Coursera course by Andrew Ng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (12, 3)\n"
     ]
    }
   ],
   "source": [
    "# Example Dataset\n",
    "\"\"\"\n",
    "The dataset that we will be using to test the PCA algorithm contains 12 examples with 3 input features.\n",
    "\"\"\"\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "\n",
    "# Creating the dataset\n",
    "X = np.array([[10,20,9.8],[15,33,9.6],[2.5, 5, 9.9], [4.8, 10, 9.8], [7.6,15,9.8],[9, 19, 9.7],\n",
    "             [3.2,6.5,9.8],[12.1,24,9.5],[14.5, 28, 9.6], [7.8, 16, 9.7], [17.6,35,9.9],[6, 11.8, 9.7]])\n",
    "\n",
    "# Printing the dataset shape\n",
    "print('X:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Principal Component Analysis\n",
    "\"\"\"\n",
    "In this section we define the PCA function using simple numpy functions. This particular PCA algorithm\n",
    "will retain 99% variance unless it is given a value for n_components when called. The function will\n",
    "print out the number of principal components and the percent variance retained. And it will return the\n",
    "data with its new features, and a reconstruction of the original data.\n",
    "\"\"\"\n",
    "def PCA(X, n_components = None):\n",
    "    \n",
    "    # Importing the libraries\n",
    "    import numpy as np\n",
    "    \n",
    "    # Singular Value Decomposition \n",
    "    cov = np.cov(np.transpose(X))\n",
    "    U, s, V = np.linalg.svd(cov) # U = eigenvectors, s = eigenvalues\n",
    "    \n",
    "    # Choosing the number of principal components\n",
    "    # Option 1: 99% variance retained\n",
    "    if n_components == None:\n",
    "        den = np.sum(s)\n",
    "        num = 0\n",
    "        for i in range (s.shape[0]):\n",
    "            num = num + s[i]\n",
    "            if num / den >= 0.99:\n",
    "                break\n",
    "        pc = i + 1\n",
    "        print('\\nVariance retained:', num / den)\n",
    "    \n",
    "    # Option 2: n_components\n",
    "    else:\n",
    "        pc = n_components\n",
    "        den = np.sum(s)\n",
    "        num = 0\n",
    "        for i in range (0, pc):\n",
    "            num = num + s[i]\n",
    "        print('Variance retained:', num / den)\n",
    "    \n",
    "    # Printing the number of principal components\n",
    "    print('Number of principal components:', pc)\n",
    "    \n",
    "    # Obtaining the principal components\n",
    "    U_reduced = U[:, :pc]\n",
    "    \n",
    "    # Creating the new X\n",
    "    X_new = np.matmul(X, U_reduced)\n",
    "    \n",
    "    # Reconstructing the original X\n",
    "    X_approx = np.matmul(X_new, np.transpose(U_reduced))\n",
    "    \n",
    "    # Returns the new X and the reconstructed X\n",
    "    return X_new, X_approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X:\n",
      " [[ 10.   20.    9.8]\n",
      " [ 15.   33.    9.6]\n",
      " [  2.5   5.    9.9]\n",
      " [  4.8  10.    9.8]\n",
      " [  7.6  15.    9.8]\n",
      " [  9.   19.    9.7]\n",
      " [  3.2   6.5   9.8]\n",
      " [ 12.1  24.    9.5]\n",
      " [ 14.5  28.    9.6]\n",
      " [  7.8  16.    9.7]\n",
      " [ 17.6  35.    9.9]\n",
      " [  6.   11.8   9.7]]\n",
      "\n",
      "X scaled:\n",
      " [[ 0.17848445  0.14756825  0.56568542]\n",
      " [ 1.26020838  1.52605014 -1.13137085]\n",
      " [-1.44410145 -1.44298777  1.41421356]\n",
      " [-0.94650844 -0.91280243  0.56568542]\n",
      " [-0.34074304 -0.38261709  0.56568542]\n",
      " [-0.03786034  0.04153118 -0.28284271]\n",
      " [-1.2926601  -1.28393217  0.56568542]\n",
      " [ 0.6328085   0.57171653 -1.97989899]\n",
      " [ 1.15203599  0.9958648  -1.13137085]\n",
      " [-0.29747408 -0.27658002 -0.28284271]\n",
      " [ 1.82270483  1.73812427  1.41421356]\n",
      " [-0.6868947  -0.7219357  -0.28284271]]\n",
      "\n",
      "Variance retained: 0.998396922998\n",
      "Number of principal components: 2\n",
      "\n",
      "New X scaled:\n",
      " [[ 0.01641276 -0.61085049]\n",
      " [-2.25912849  0.24567843]\n",
      " [ 2.43782797 -0.47385077]\n",
      " [ 1.43118265  0.0110265 ]\n",
      " [ 0.69583557 -0.31255639]\n",
      " [-0.11620471  0.25853293]\n",
      " [ 1.89559376  0.21477462]\n",
      " [-1.57590214  1.4696818 ]\n",
      " [-1.84534593  0.4238508 ]\n",
      " [ 0.25789442  0.42233612]\n",
      " [-1.73657635 -2.30787077]\n",
      " [ 0.79841048  0.65924722]]\n",
      "\n",
      "Reconstruction of X scaled:\n",
      " [[  1.67900917e-01   1.58214717e-01   5.65848998e-01]\n",
      " [  1.38814516e+00   1.39735263e+00  -1.13334817e+00]\n",
      " [ -1.43694961e+00  -1.45018213e+00   1.41410303e+00]\n",
      " [ -9.28109746e-01  -9.31310524e-01   5.65401066e-01]\n",
      " [ -3.58339123e-01  -3.64916373e-01   5.65957380e-01]\n",
      " [ -4.54376816e-04   3.90280205e-03  -2.83420837e-01]\n",
      " [ -1.28777166e+00  -1.28884967e+00   5.65609872e-01]\n",
      " [  5.88929128e-01   6.15856812e-01  -1.97922081e+00]\n",
      " [  1.06867539e+00   1.07972107e+00  -1.13008248e+00]\n",
      " [ -2.90080051e-01  -2.84018016e-01  -2.82956990e-01]\n",
      " [  1.79666915e+00   1.76431476e+00   1.41461595e+00]\n",
      " [ -7.08615170e-01  -7.00086079e-01  -2.82507014e-01]]\n",
      "\n",
      "Reconstruction of original X:\n",
      " [[  9.95108025  20.10040322   9.80001928]\n",
      " [ 15.59135595  31.78629697   9.59976697]\n",
      " [  2.53305759   4.93215238   9.89998697]\n",
      " [  4.88504339   9.82545635   9.79996649]\n",
      " [  7.51866647  15.16692949   9.80003205]\n",
      " [  9.17289976  18.64513935   9.69993187]\n",
      " [  3.22259561   6.45362462   9.7999911 ]\n",
      " [ 11.89717851  24.41627223   9.50007992]\n",
      " [ 14.11468634  28.7908204    9.60015184]\n",
      " [  7.83417707  15.92985475   9.69998653]\n",
      " [ 17.47965655  35.24699373   9.90004742]\n",
      " [  5.89960251  12.00605649   9.70003956]]\n"
     ]
    }
   ],
   "source": [
    "# Principal Component Analysis\n",
    "\"\"\"\n",
    "Test the PCA algorithm above and compare the original data X with the new X and the reconstructed X.\n",
    "Usually we scale the data X before applying PCA.\n",
    "\"\"\"\n",
    "# Feature scaling and normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "# Printing the original data X\n",
    "print('Original X:\\n', X)\n",
    "\n",
    "# Printing the scaled data X\n",
    "print('\\nX scaled:\\n', X_scaled)\n",
    "\n",
    "# Applying PCA to scaled X\n",
    "X_scaled_new, X_scaled_approx = PCA(X_scaled)\n",
    "\n",
    "# Printing the new scaled X\n",
    "print('\\nNew X scaled:\\n', X_scaled_new)\n",
    "\n",
    "# Printing the reconstructed scaled X\n",
    "print('\\nReconstruction of X scaled:\\n', X_scaled_approx)\n",
    "\n",
    "# Printing the reconstructed original X\n",
    "print('\\nReconstruction of original X:\\n', scaler_X.inverse_transform(X_scaled_approx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X:\n",
      " [[ 10.   20.    9.8]\n",
      " [ 15.   33.    9.6]\n",
      " [  2.5   5.    9.9]\n",
      " [  4.8  10.    9.8]\n",
      " [  7.6  15.    9.8]\n",
      " [  9.   19.    9.7]\n",
      " [  3.2   6.5   9.8]\n",
      " [ 12.1  24.    9.5]\n",
      " [ 14.5  28.    9.6]\n",
      " [  7.8  16.    9.7]\n",
      " [ 17.6  35.    9.9]\n",
      " [  6.   11.8   9.7]]\n",
      "\n",
      "X scaled:\n",
      " [[ 0.17848445  0.14756825  0.56568542]\n",
      " [ 1.26020838  1.52605014 -1.13137085]\n",
      " [-1.44410145 -1.44298777  1.41421356]\n",
      " [-0.94650844 -0.91280243  0.56568542]\n",
      " [-0.34074304 -0.38261709  0.56568542]\n",
      " [-0.03786034  0.04153118 -0.28284271]\n",
      " [-1.2926601  -1.28393217  0.56568542]\n",
      " [ 0.6328085   0.57171653 -1.97989899]\n",
      " [ 1.15203599  0.9958648  -1.13137085]\n",
      " [-0.29747408 -0.27658002 -0.28284271]\n",
      " [ 1.82270483  1.73812427  1.41421356]\n",
      " [-0.6868947  -0.7219357  -0.28284271]]\n",
      "\n",
      "Variance retained: 0.998396922998\n",
      "Number of principal components: 2\n",
      "\n",
      "New X scaled:\n",
      " [[ 0.01641276  0.61085049]\n",
      " [-2.25912849 -0.24567843]\n",
      " [ 2.43782797  0.47385077]\n",
      " [ 1.43118265 -0.0110265 ]\n",
      " [ 0.69583557  0.31255639]\n",
      " [-0.11620471 -0.25853293]\n",
      " [ 1.89559376 -0.21477462]\n",
      " [-1.57590214 -1.4696818 ]\n",
      " [-1.84534593 -0.4238508 ]\n",
      " [ 0.25789442 -0.42233612]\n",
      " [-1.73657635  2.30787077]\n",
      " [ 0.79841048 -0.65924722]]\n",
      "\n",
      "Reconstruction of X scaled:\n",
      " [[  1.67900917e-01   1.58214717e-01   5.65848998e-01]\n",
      " [  1.38814516e+00   1.39735263e+00  -1.13334817e+00]\n",
      " [ -1.43694961e+00  -1.45018213e+00   1.41410303e+00]\n",
      " [ -9.28109746e-01  -9.31310524e-01   5.65401066e-01]\n",
      " [ -3.58339123e-01  -3.64916373e-01   5.65957380e-01]\n",
      " [ -4.54376816e-04   3.90280205e-03  -2.83420837e-01]\n",
      " [ -1.28777166e+00  -1.28884967e+00   5.65609872e-01]\n",
      " [  5.88929128e-01   6.15856812e-01  -1.97922081e+00]\n",
      " [  1.06867539e+00   1.07972107e+00  -1.13008248e+00]\n",
      " [ -2.90080051e-01  -2.84018016e-01  -2.82956990e-01]\n",
      " [  1.79666915e+00   1.76431476e+00   1.41461595e+00]\n",
      " [ -7.08615170e-01  -7.00086079e-01  -2.82507014e-01]]\n",
      "\n",
      "Reconstruction of original X:\n",
      " [[  9.95108025  20.10040322   9.80001928]\n",
      " [ 15.59135595  31.78629697   9.59976697]\n",
      " [  2.53305759   4.93215238   9.89998697]\n",
      " [  4.88504339   9.82545635   9.79996649]\n",
      " [  7.51866647  15.16692949   9.80003205]\n",
      " [  9.17289976  18.64513935   9.69993187]\n",
      " [  3.22259561   6.45362462   9.7999911 ]\n",
      " [ 11.89717851  24.41627223   9.50007992]\n",
      " [ 14.11468634  28.7908204    9.60015184]\n",
      " [  7.83417707  15.92985475   9.69998653]\n",
      " [ 17.47965655  35.24699373   9.90004742]\n",
      " [  5.89960251  12.00605649   9.70003956]]\n"
     ]
    }
   ],
   "source": [
    "# PCA w/ sklearn\n",
    "\"\"\"\n",
    "Here instead of using our own function, we apply PCA from the sklearn library.\n",
    "\"\"\"\n",
    "# Feature scaling and normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "# Printing the original data X\n",
    "print('Original X:\\n', X)\n",
    "\n",
    "# Printing the scaled data X\n",
    "print('\\nX scaled:\\n', X_scaled)\n",
    "\n",
    "# Creating and fitting PCA to the dataset\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2)\n",
    "X_scaled_new = pca.fit_transform(X_scaled)\n",
    "X_scaled_approx = pca.inverse_transform(X_scaled_new)\n",
    "\n",
    "# Printing the percent variance retained and the number of principal components\n",
    "print('\\nVariance retained:', np.sum(pca.explained_variance_ratio_))\n",
    "print('Number of principal components:', pca.n_components_)\n",
    "\n",
    "# Printing the new scaled X\n",
    "print('\\nNew X scaled:\\n', X_scaled_new)\n",
    "\n",
    "# Printing the reconstructed scaled X\n",
    "print('\\nReconstruction of X scaled:\\n', X_scaled_approx)\n",
    "\n",
    "# Printing the reconstructed original X\n",
    "print('\\nReconstruction of original X:\\n', scaler_X.inverse_transform(X_scaled_approx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b78ccc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing new data X\n",
    "\"\"\"\n",
    "One of the main reasons PCA is used is to lower the dimension of some dataset so that it can be\n",
    "visualized on a 2D plane. Here we plot the new scaled X calculated above.\n",
    "\"\"\"\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Plotting the new scaled data X\n",
    "plt.plot(X_scaled_new[:, 0], X_scaled_new[:, 1], 'ro')\n",
    "\n",
    "plt.title('New scaled X')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
